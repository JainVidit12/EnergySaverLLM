{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87a9a772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from eventlet.timeout import Timeout\n",
    "\n",
    "# import auxillary packages\n",
    "import requests  # for loading the example source code\n",
    "import openai\n",
    "import json\n",
    "\n",
    "# import flaml and autogen\n",
    "from flaml import autogen\n",
    "from flaml.autogen.agentchat import Agent, UserProxyAgent\n",
    "from EnergySaverLLM.Agent import ChargingAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cb9a00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = autogen.config_list_from_json(\n",
    "    env_or_file = \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4\", \"gpt-3.5-turbo\"],\n",
    "        # \"model\": [\"gpt-3.5-turbo\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebbceda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "autogen.oai.ChatCompletion.start_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e94b994",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_path = \"EnergySaverLLM/Model/EVCharging.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76c37670",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(code_path) as f:\n",
    "    code = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9adda55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global params_filepath\n",
    "params_filepath = \"EnergySaverLLM/Model/params/EVCharging.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d763b012",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(params_filepath) as f:\n",
    "    json = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81dd0c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from datetime import datetime\n",
      "from gurobipy import GRB, Model\n",
      "import json\n",
      "\n",
      "# Fetching data from JSON file\n",
      "\n",
      "params_filepath = \"EnergySaverLLM/Model/params/EVCharging.json\"\n",
      "\n",
      "stored_params = json.load(open(params_filepath))\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "    values = model.getAttr(\"X\", all_vars)\n",
      "    names = model.getAttr(\"VarName\", all_vars)\n",
      "\n",
      "    for i, time_str in enumerate(keys):\n",
      "        if(values[i]>0):\n",
      "            print(f\"Scheduled consumption at Hour {time_str} : {int(values[i]):d} KWH\")\n",
      "\n",
      "else:\n",
      "    print(\"Not solved to optimality. Optimization status:\", model.status)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the first head and tail of the source code\n",
    "print(\"\\n\".join(code.split(\"\\n\")[:10]))\n",
    "print(\".\\n\" * 3)\n",
    "print(\"\\n\".join(code.split(\"\\n\")[-10:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9adce8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_qa = \"\"\"\n",
    "----------\n",
    "Instruction: Don't charge the car from 8 PM to 10 PM\n",
    "Answer Code:\n",
    "```python\n",
    "upper_bounds[20:22] = [0]*(22-20)\n",
    "```\n",
    "\n",
    "----------\n",
    "Question: Electricity costs are have been increased by 30%, adjust the schedule accordingly\n",
    "Answer Code:\n",
    "```python\n",
    "elec_costs.update((x, y*1.3) for x, y in elec_costs.items())\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b9b6c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "agent = ChargingAgent(\n",
    "    name=\"Tesla Charging Example\",\n",
    "    source_code=code,\n",
    "    debug_times=1,\n",
    "    example_qa=example_qa,\n",
    "    json=json,\n",
    "    llm_config={\n",
    "        \"request_timeout\": 600,\n",
    "        \"seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "    }\n",
    ")\n",
    "\n",
    "user = UserProxyAgent(\n",
    "    \"user\", max_consecutive_auto_reply=0,\n",
    "    human_input_mode=\"NEVER\", code_execution_config=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cede6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e162e7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser\u001b[0m (to Tesla Charging Example):\n",
      "\n",
      "Turn charging off between 12 AM and 4 AM tonight\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mTesla Charging Example\u001b[0m (to writer):\n",
      "\n",
      "\n",
      "Answer Code:\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mwriter\u001b[0m (to Tesla Charging Example):\n",
      "\n",
      "```python\n",
      "upper_bounds[24:28] = [0] * (28 - 24)\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mTesla Charging Example\u001b[0m (to safeguard):\n",
      "\n",
      "\n",
      "--- Code ---\n",
      "upper_bounds[24:28] = [0] * (28 - 24)\n",
      "\n",
      "--- One-Word Answer: SAFE or DANGER ---\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33msafeguard\u001b[0m (to Tesla Charging Example):\n",
      "\n",
      "SAFE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "{'0': 0.3, '1': 0.3, '2': 0.3, '3': 0.3, '4': 0.3, '5': 0.3, '6': 0.3, '7': 0.35, '8': 0.35, '9': 0.35, '10': 0.35, '11': 0.3, '12': 0.3, '13': 0.3, '14': 0.3, '15': 0.3, '16': 0.3, '17': 0.3, '18': 0.3, '19': 0.35, '20': 0.35, '21': 0.35, '22': 0.3, '23': 0.3}\n",
      "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (mac64[arm])\n",
      "\n",
      "CPU model: Apple M1\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 2 rows, 48 columns and 96 nonzeros\n",
      "Model fingerprint: 0x0f466f6d\n",
      "Variable types: 0 continuous, 48 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [3e-01, 1e+00]\n",
      "  Objective range  [8e+00, 8e+00]\n",
      "  Bounds range     [1e+01, 1e+01]\n",
      "  RHS range        [2e+01, 5e+01]\n",
      "Presolve removed 2 rows and 48 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 8 available processors)\n",
      "\n",
      "Solution count 1: 383 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.830000000000e+02, best bound 3.830000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (mac64[arm])\n",
      "\n",
      "CPU model: Apple M1\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 2 rows, 48 columns and 96 nonzeros\n",
      "Model fingerprint: 0x0f466f6d\n",
      "Variable types: 0 continuous, 48 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [3e-01, 1e+00]\n",
      "  Objective range  [8e+00, 8e+00]\n",
      "  Bounds range     [1e+01, 1e+01]\n",
      "  RHS range        [2e+01, 5e+01]\n",
      "\n",
      "\n",
      "Presolve removed 2 rows and 48 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 1 (of 8 available processors)\n",
      "\n",
      "Solution count 1: 383 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.830000000000e+02, best bound 3.830000000000e+02, gap 0.0000%\n",
      "Optimal Charging Schedule:\n",
      "Scheduled consumption at Hour 20 : 5 KWH\n",
      "Scheduled consumption at Hour 21 : 11 KWH\n",
      "Scheduled consumption at Hour 22 : 11 KWH\n",
      "Scheduled consumption at Hour 23 : 11 KWH\n",
      "Scheduled consumption at Hour 28 : 11 KWH\n",
      "\u001b[33mOptimization problem solved. The objective value is: 383.0\u001b[0m\n",
      "\u001b[33mTesla Charging Example\u001b[0m (to writer):\n",
      "\n",
      "Here are the execution results: Optimization problem solved. The objective value is: 383.0\n",
      "\n",
      "Can you organize these information to a human readable answer?\n",
      "Remember to compare the new results to the original results you obtained in the\n",
      "beginning.\n",
      "\n",
      "--- HUMAN READABLE ANSWER ---\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mwriter\u001b[0m (to Tesla Charging Example):\n",
      "\n",
      "I have updated the charging schedule to turn off charging between 12 AM and 4 AM tonight. \n",
      "\n",
      "After these changes, we re-optimized the charging plan, and the total objective function value (which accounts for both electricity cost and carbon emissions) is now 383.0. This is slightly higher than the original cost of 382.2, a small increase might be due to the smaller feasible charging time window. This suggests that turning off the charging during the specified time could result in a slightly higher cost due to the electricity cost variations and the constraints of the charging planning problem.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mTesla Charging Example\u001b[0m (to user):\n",
      "\n",
      "I have updated the charging schedule to turn off charging between 12 AM and 4 AM tonight. \n",
      "\n",
      "After these changes, we re-optimized the charging plan, and the total objective function value (which accounts for both electricity cost and carbon emissions) is now 383.0. This is slightly higher than the original cost of 382.2, a small increase might be due to the smaller feasible charging time window. This suggests that turning off the charging during the specified time could result in a slightly higher cost due to the electricity cost variations and the constraints of the charging planning problem.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user.initiate_chat(agent, message=\"Turn charging off between 12 AM and 4 AM tonight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8784224d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser\u001b[0m (to Tesla Charging Example):\n",
      "\n",
      "Reduce max allowed electricity cost to 15 dollars\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mTesla Charging Example\u001b[0m (to writer):\n",
      "\n",
      "\n",
      "Answer Code:\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mwriter\u001b[0m (to Tesla Charging Example):\n",
      "\n",
      "```python\n",
      "max_elec_cost = 15\n",
      "model.addConstr(sum(x[i] * elec_costs[i] for i in keys) <= max_elec_cost)\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mTesla Charging Example\u001b[0m (to safeguard):\n",
      "\n",
      "\n",
      "--- Code ---\n",
      "max_elec_cost = 15\n",
      "model.addConstr(sum(x[i] * elec_costs[i] for i in keys) <= max_elec_cost)\n",
      "\n",
      "--- One-Word Answer: SAFE or DANGER ---\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33msafeguard\u001b[0m (to Tesla Charging Example):\n",
      "\n",
      "SAFE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "{'0': 0.3, '1': 0.3, '2': 0.3, '3': 0.3, '4': 0.3, '5': 0.3, '6': 0.3, '7': 0.35, '8': 0.35, '9': 0.35, '10': 0.35, '11': 0.3, '12': 0.3, '13': 0.3, '14': 0.3, '15': 0.3, '16': 0.3, '17': 0.3, '18': 0.3, '19': 0.35, '20': 0.35, '21': 0.35, '22': 0.3, '23': 0.3}\n",
      "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (mac64[arm])\n",
      "\n",
      "CPU model: Apple M1\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 2 rows, 48 columns and 96 nonzeros\n",
      "Model fingerprint: 0x959f99f2\n",
      "Variable types: 0 continuous, 48 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [3e-01, 1e+00]\n",
      "  Objective range  [8e+00, 8e+00]\n",
      "  Bounds range     [1e+01, 1e+01]\n",
      "  RHS range        [2e+01, 5e+01]\n",
      "Presolve removed 2 rows and 48 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 1 (of 8 available processors)\n",
      "\n",
      "Solution count 1: 382.2 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.822000000000e+02, best bound 3.822000000000e+02, gap 0.0000%\n",
      "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (mac64[arm])\n",
      "\n",
      "CPU model: Apple M1\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 3 rows, 48 columns and 144 nonzeros\n",
      "Model fingerprint: 0x88aeafca\n",
      "Variable types: 0 continuous, 48 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [3e-01, 1e+00]\n",
      "  Objective range  [8e+00, 8e+00]\n",
      "  Bounds range     [1e+01, 1e+01]\n",
      "  RHS range        [2e+01, 5e+01]\n",
      "\n",
      "Loaded MIP start from previous solve with objective 382.2\n",
      "\n",
      "Presolve removed 3 rows and 48 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 1 (of 8 available processors)\n",
      "\n",
      "Solution count 1: 382.2 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.822000000000e+02, best bound 3.822000000000e+02, gap 0.0000%\n",
      "Optimal Charging Schedule:\n",
      "Scheduled consumption at Hour 22 : 11 KWH\n",
      "Scheduled consumption at Hour 24 : 5 KWH\n",
      "Scheduled consumption at Hour 25 : 11 KWH\n",
      "Scheduled consumption at Hour 26 : 11 KWH\n",
      "Scheduled consumption at Hour 27 : 11 KWH\n",
      "\u001b[33mOptimization problem solved. The objective value is: 382.2\u001b[0m\n",
      "\u001b[33mTesla Charging Example\u001b[0m (to writer):\n",
      "\n",
      "Here are the execution results: Optimization problem solved. The objective value is: 382.2\n",
      "\n",
      "Can you organize these information to a human readable answer?\n",
      "Remember to compare the new results to the original results you obtained in the\n",
      "beginning.\n",
      "\n",
      "--- HUMAN READABLE ANSWER ---\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mwriter\u001b[0m (to Tesla Charging Example):\n",
      "\n",
      "After reducing the max allowed electricity cost to 15 dollars, the optimization problem was still solved successfully. However, the objective value remained the same at 382.2. This might be due to the fact that the original optimal solution already achieved a total cost less than or equal to 15 dollars. Therefore, the constraint change didn't affect the solution. \n",
      "\n",
      "It's always good to keep in mind that changes in constraints can potentially affect the optimal solution, but whether it actually does depends on the specifics of the problem and the original optimal solution.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mTesla Charging Example\u001b[0m (to user):\n",
      "\n",
      "After reducing the max allowed electricity cost to 15 dollars, the optimization problem was still solved successfully. However, the objective value remained the same at 382.2. This might be due to the fact that the original optimal solution already achieved a total cost less than or equal to 15 dollars. Therefore, the constraint change didn't affect the solution. \n",
      "\n",
      "It's always good to keep in mind that changes in constraints can potentially affect the optimal solution, but whether it actually does depends on the specifics of the problem and the original optimal solution.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user.initiate_chat(agent, message=\"Reduce max allowed electricity cost to 15 dollars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d8db60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922fb36e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
